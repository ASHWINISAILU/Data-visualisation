---
title: "An analysis of a policing dataset from Colchester in 2023"
output:
  html_document: default
  pdf_document: default
  word_document: default
date: "2024-04-18"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(warning = FALSE, message = FALSE)
```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
summary(cars)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```

Note that the `echo = FALSE` parameter was added to the code chunk to prevent printing of the R code that generated the plot.

INTRODUCTION:

We are analyzing the policing dataset from Colchester in the year 2023. Two datasets namely crime and temp2023 are analysed here under variable crime_data1 and temp_data2.Crime_data1 consists of information related to crime types, locations, latitude, longitude, street ID, street name, etc related to crime from Colchester over the year 2023. temp_data2 consists of weather details of station ID 3590 close to Colchester. So Let's assume that the weather data is related to Colchester over the year 2023.

```{r}
# importing required libraries
library(xfun)
library(tidyr)
library(dplyr)
library(kableExtra)
library(ggplot2)
library(plotly)
library(ggiraph)
library(leaflet)
library(lubridate)
library(gridExtra)
library(reshape2)


```

```{r}
#import the two dataset for analysis
crime_data1=read.csv("D:/MA304 Data visualisation/crime23.csv")
temp_data2=read.csv("D:/MA304 Data visualisation/temp2023.csv")
# to find the number of rows and columns in the dataset
dim(crime_data1)
dim(temp_data2)
#Summarise the dataset
summary(crime_data1)
summary(temp_data2)
```
crime_data1 contains 6878 rows and 12 columns, temp_data2 contains 365 rows and 18 columns.
The summary of the two datasets shows the details of each column to understand the nature, class, number of NA values, mean, and median if the columns contain numeric data.
Crime_data1 contains numeric datatype in lat, long, and id and the rest of the columns have character class datatype.
temp_data2 contains numeric datatype stationID, TemperatureCAvg, TemperatureCMax, TemperatureCMin, TdAvgC, HrAvg, WindkmhInt, WindkmhGust, PresslevHp, Precmm, TotClOct,lowClOct, SunD1h, VisKm, PreselevHp, SnowDepc and character class datatype as Date, WindkmhDir, etc. We see in temp_data2 station ID 3590 is constant and the whole report is related to one station ID i.e. 3590.

```{r}
#Preprocessing the data crime_data1
#checking on NA values
crime_data1_na<- colSums(is.na(crime_data1))
crime_data1_na

# removing the column "context" as  it contains all null values
crime_data1<- crime_data1[,!(names(crime_data1)=="context")]

# Fill missing values as "unknown" for "location_subtype" based on "location_type"
crime_data1$location_subtype[crime_data1$location_type == "Force" & is.na(crime_data1$location_subtype)] <- "Unknown"


```
As part of data pre-processing on the crime data. We have filtered the na values. We could see the main columns have all the details except a few columns where null values were cited such as persistent_id, context id,location_subtype, and outcome_status. We have removed the column context from the dataset as contains no values and removing the column doesn't impact the dataset. Also, we have filled the location sub_type as unknown to the null value columns.


```{r}

two_way_table_with_margins<-table(crime_data1$location_type,crime_data1$category)

# Convert the table to a data frame
two_way_df <- as.data.frame.matrix(two_way_table_with_margins)

# Add row names for better clarity
row_names <- rownames(two_way_df)
row_names[length(row_names)] <- "Total"

# Set the row names
rownames(two_way_df) <- row_names

# Add column names for better clarity
col_names <- colnames(two_way_df)
col_names[length(col_names)] <- "Total"

# Set the column names
colnames(two_way_df) <- col_names

two_way_df

```
The above table shows the number of location_type and category of crime accordingly. Location BTP has a very low rate of crime when compared to Force location_type.



```{r}

# Calculate count of each category within each location type
category_counts <- crime_data1 %>%
  group_by(location_type, category,.groups = "drop") %>%
  summarise(count = n())

# Create a scatter plot
scatter_plot <- ggplot(category_counts, aes(x = location_type, y = count, color = category)) +
  geom_point(position = position_dodge(width = 0.5), size = 3) +
  labs(title = "Distribution of Categories based on Location Type", x = "Location Type", y = "Count") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

# Print the scatter plot
print(scatter_plot)

```
The above scatter plot shows the distribution of different categories of crimes in Colchester in 2023 based on the location_type named BTP and Force. Force location_type has increased crime rate when compared to BTP which maintains the crime rate at minimal.


```{r}
# count of each category
Count_on_category <- count(crime_data1, category)

# Calculate percentile
Count_on_category <- mutate(Count_on_category, percent = prop.table(n) * 100)

# Sort by frequency
Count_on_category <- arrange(Count_on_category, desc(n))

# Create a ggplot interactive features using ggiraph
pie_ggplot <- ggplot(Count_on_category, aes(x = "", y = percent, fill = category, tooltip = paste(category, ": ", round(percent, 2), "%"))) +
  geom_bar_interactive(stat = "identity", width = 1) +
  geom_text(aes(label = paste0(round(percent, 2), "%")), position = position_stack(vjust =0.5)) + 
  coord_polar("y", start = 0) +
  labs(title = "Categories of crime in Colchester in 2023", fill = "Category", x = NULL, y = NULL) +
  theme_void()

# Print the ggiraph plot
girafe(code = print(pie_ggplot))

```

The above pie chart shows the rate of each crime category in Colchester for the year 2023. Interactive functions are used to show the crime and its rate based on the color to give better visualization to see the percentage for the minimal margin crimes as well. violent crime has the highest contribution of 38.28% and the least crime recorded is possession of weapons of 1.08%.


```{r}

# calculate the mode of each street name with crime
mode_streetname <- crime_data1 %>%
  group_by(street_name) %>%
  summarise(count = n()) %>%
  arrange(desc(count)) %>%
  top_n(10)

# Create a bar plot of the top 10 street names which records highest crimes
ggplot(mode_streetname, aes(x = reorder(street_name, -count), y = count)) +
  geom_bar(stat = "identity", fill = "skyblue") +
  geom_text(aes(label = count), vjust = -0.5, color = "black", size = 3) +
  labs(title = "Top 10 Street Names recording high crimes in Colchester in 2023", x = "Street Name", y = "count of crimes") +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

```

The above bar chart shows the top 10 street names recorded with the highest crimes in Colchester year 2023. This shows the street name on or near records the highest crime count of 495 in the year 2023.

```{r}
#Extracting month from date column from crime_data1

# Extract month part from date column and store it in a new column named "month"
crime_data1$month <- as.integer(substr(crime_data1$date, 6, 7))

# View the structure of the new "month" column
str(crime_data1$month)

```

```{r}
# Create a ggplot object
plot <- ggplot(crime_data1, aes(x = factor(month), fill = category)) +
  geom_bar(position = "stack") +
  labs(title = "Crime Distribution by category over the months in 2023",
       x = "Month",
       y = "Count",
       fill = "Category") +
  theme_minimal() +
  theme(legend.position = "right")

# Print the plot
print(plot)

```
The above graph shows the different crime categories recorded for each month. The volume of the crime is recorded by the color. Violent crime captures most of all the months. January and September record more crimes when compared to the other months.

```{r}

# Count the number of crimes for each month
monthly_counts <- count(crime_data1, month)

# Sort the monthly counts in descending order
monthly_counts <- monthly_counts[order(-monthly_counts$n), ]

# Convert month_numeric to numeric
monthly_counts$month_numeric <- as.numeric(factor(monthly_counts$month))

# Create the bar graph
bar_plot <- ggplot(monthly_counts, aes(x = month_numeric, y = n)) +
  geom_bar(stat = "identity", fill = "skyblue", color = "black") +
  geom_text(aes(label = n), vjust = -0.5, color = "black", size = 3) +
  labs(title = " Crime record in Colchester for the year 2023",
       x = "Month", y = "Number of Crimes") +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +
  theme_classic() +
  theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

# Print the bar graph
print(bar_plot)
```
The graph shows the recorded crime in Colchester for the year 2023. The count of recorded crimes for each month is visualized here. The trend shows that during the summer and autumn seasons, the crime rates are highly recorded as the people gatherings are much sited during these months. September records the second highest of 642 crimes across Colchester as it is the start of the new academic year in universities, colleges, and schools. and January captures the highest 651 crime count as it is very evident of the new year season and celebration.

```{r}

# Group by street_name and count the occurrences
street_counts <- crime_data1 %>%
  group_by(street_name) %>%
  summarise(total_count = n())

# Get the top 10 streets with the highest crime occurrences from the data crime_data1
top_streets <- street_counts %>%
  top_n(10, total_count) %>%
  pull(street_name)

# Group by category and count the occurrences
category_counts <- crime_data1 %>%
  group_by(category) %>%
  summarise(total_count = n())

# Get the top 5 categories from the data crime_data1
top_categories <- category_counts %>%
  top_n(5, total_count) %>%
  pull(category)

# Filtering the data to include only the top 5 categories and top 10 streets
crime_data_filtered <- crime_data1 %>%
  filter(category %in% top_categories, street_name %in% top_streets) %>%
  select(category, month, street_name)

# Create a Plotly plot
plot <- plot_ly(data = crime_data_filtered, x = ~month, color = ~category) %>%
  add_markers(y = ~street_name, hoverinfo = "text",
              text = ~paste("Category: ", category, "<br>",
                             "Month: ", month, "<br>",
                             "Street Name: ", street_name)) %>%
  layout(title = "Top 5 Categories of Crime each Month recorded on top 10 crime streets")

# Show the plot
plot
```

The above interactive dot plot shows the distribution of different categories of crime over high-crime streets over the year 2023. This gives a details look at each crime over different months in high-crime streets. majority of the crimes captured are due to violence. When u want to zoom in to look out on the detailed crime time, it gives more visibility.

```{r}
library(leaflet.extras)

# Create leaflet map
map <- leaflet(crime_data1) %>%
  
  # Add tiles for the base map
  addTiles() %>%
  
  # Adding marers for each crime with latitude and longtitude with category of crime
  addMarkers(
    lng = ~long,
    lat = ~lat,
    popup = ~category,  # Display category as popup when clicked
    clusterOptions = markerClusterOptions()  # Cluster markers for better visualization
  ) %>%
  
  # Set map view to center around the data points
  fitBounds(~min(long), ~min(lat), ~max(long), ~max(lat))
  # title of the map
  map <- addControl(map, html = "<h2>Crime across Colchester for the year 2023</h2>", position = "topright")

# Print the map
map

```

The data on the crime are visualized through the map. based on the latitude and longitude we have marked the different categories of crime recorded in each area in Colchester. This helps to explore more high and low crime areas, planning on people's safety. Areas to increase policing activities can also be found out easily. At each cluster point, we can zoom in and find out at street level the category of crime recorded over the areas as well. This gives us a wider picture of crime happenings in Colchester in 2023 over a map for better understanding.

```{r}
### Analysis of weather in colchester for year 2023 station id 3590

# to fill the missing values.
# Check for missing values in each column
missing_values <- colSums(is.na(temp_data2))

# Print columns with missing values
print(names(temp_data2)[missing_values > 0])

missing_values <- colSums(is.na(temp_data2))

# Replace missing values in "Precmm" column with mean of non-missing values
temp_data2$Precmm <- ifelse(is.na(temp_data2$Precmm), mean(temp_data2$Precmm, na.rm = TRUE), temp_data2$Precmm)

# Replace missing values in "lowClOct" column with the mode of non-missing values
most_frequent_lowClOct <- names(sort(table(temp_data2$lowClOct), decreasing = TRUE))[1]
temp_data2$lowClOct[is.na(temp_data2$lowClOct)] <- most_frequent_lowClOct

# Replace missing values in "SunD1h" column with mean of non-missing values
temp_data2$SunD1h <- ifelse(is.na(temp_data2$SunD1h), mean(temp_data2$SunD1h, na.rm = TRUE), temp_data2$SunD1h)

# Replace missing values in "SnowDepcm" column with 0
temp_data2$SnowDepcm[is.na(temp_data2$SnowDepcm)] <- 0

#Remove column PreselevHp as only NA values are present.
#Remove stationID as its constant as 3590 across all rows.

temp_data2 <- subset(temp_data2, select = -c(station_ID, PreselevHp))


```
Pre-processing of temp_data2 consists of removing the NA values and filling the null values. Since column PreselevHp has only NA values and station_ID values are constant in all rows. we have removed these two columns from the temp_data2 dataset, as their values don't affect the quality of the data. Missing values of columns were minimal so we have used mean values of their respective columns for Precmm & SunD1h and mode value for lowClOct column.


```{r}
## Box plot

# Select only numeric columns
numeric_data <- temp_data2 %>%
  select(where(is.numeric))

# Convert the dataset to a long format
long_data <- pivot_longer(numeric_data, cols = everything(), names_to = "Variable", values_to = "Value")

ggplot(long_data, aes(x = Variable, y = Value)) +
  geom_boxplot() +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1)) +
  labs(title = "Boxplot of Numeric Variables in Temperature Data",
       x = "Variables",
       y = "Values")


```
The above box plot shows the boxplot for a column with numeric data type in the dataset. Since this is related data, there seems to be not much changes in the data range and the outliers are also very minimal.

```{r}
#Reformatting the Date column DD-MM-YYYY to MM
# Convert 'Date' column to Date type
temp_data2$Date <- as.Date(temp_data2$Date)

# Extract month from the 'Date' column
temp_data2$Month <- month(temp_data2$Date)

```
Since the data is date-based information, we trying to format it from DD-MM-YYYY to the new column Month with format MM  for further analysis.

```{r}
#Analysis of temp2023 dataset showing the high and low temperature over each month.
# Group by month and calculate the max and min temperatures
temp_monthly <- temp_data2 %>%
  group_by(Month) %>%
  summarise(
    Max_Temp = max(TemperatureCMax),
    Min_Temp = min(TemperatureCMin),
  )

# Create a graph for high and low temperatures
ggplot(temp_monthly, aes(x = Month)) +
  geom_line(aes(y = Max_Temp, color = "High Temp"), size = 1) +
  geom_point(aes(y = Max_Temp, color = "High Temp"), size = 3) +
  geom_line(aes(y = Min_Temp, color = "Low Temp"), size = 1) +
  geom_point(aes(y = Min_Temp, color = "Low Temp"), size = 3) +
  geom_text(aes(y = Max_Temp, label = Max_Temp), vjust = -0.5, color = "red")+
  geom_text(aes(y = Min_Temp, label = Min_Temp), vjust = -0.5, color = "blue")+
  labs(title = "Maximum and Minimum temperature recorded in station 3590 for year 2023",
       x = "Month", y = "Temperature (Â°C)") +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +
  scale_color_manual(name = "Temperature",
                     values = c("High Temp" = "red", "Low Temp" = "blue"),
                     labels = c("High Temp", "Low Temp")) +
  theme_minimal() +
  theme(legend.position = "right")

```
The above graph shows the trend in temperature for the year 2023. January and December have recorded very low temperatures. and temperature has risen at its highest during June, July, August, and September months.

```{r}
# Analyzing the other weather scales of colchester for year 2023.

# Group by month and computing the sum , mean and max of weather scale
temp_monthly <- temp_data2 %>%
  group_by(Month) %>%
  summarise(
    Precmm = sum(Precmm),
    SunD1h = sum(SunD1h),
    VisKm = mean(VisKm),
    SnowDepcm = max(SnowDepcm)
  )

# Creating a graph to see the weather trend in colchester in 2023.
ggplot(temp_monthly, aes(x = Month)) +
  geom_line(aes(y = Precmm, color = "Precmm"), linetype = "dashed",size = 1) +
  geom_line(aes(y = SunD1h, color = "SunD1h"), linetype = "dashed",size = 1) +
  geom_line(aes(y = VisKm, color = "VisKm"), linetype = "dashed",size = 1) +
  geom_line(aes(y = SnowDepcm, color = "SnowDepcm"), linetype = "dashed",size = 1) +
  labs(title = "Analysis on weather trends in Station ID 3590 for year 2023",
       x = "Month", y = "Value") +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +
  scale_color_manual(name = "Variables",
                     values = c("Precmm" = "green", "SunD1h" = "orange",
                                "VisKm" = "purple", "SnowDepcm" = "brown"),
                     labels = c("Precmm", "SunD1h", "VisKm", "SnowDepcm")) +
  theme_minimal() +
  theme(legend.position = "top")

```

The above line plot gives a clear picture of weather trends recorded in station ID 3590 near Colchester.
Premium: This shows the total rainfall recorded at the weather station ID 3590 mm. The rainfall was high during July, and August and peaked in October months.
SunD1h: Represent the duration of sunshine recorded at the weather( in hours). The sunlight recorded seems to be on the same baseline, there wasn't much change in the sunshine recorded.
VisKm: Represent the visibility recorded at the weather station( in km). The visibility factor of the weather affects the many factors in crime categories. In Colchester
SnowDepcm: This shows the snow depth recorded at the weather station measured in centimeters (cm). There is not much variation recorded over the year 2023.

```{r}

#We are calculation average temperature of every month and create a new column ("TemperatureCAvg_monthly") in the datset temp_data2 and name it as temp_data2new

# Group temperature data by month and calculate average temperature
temp_monthly_avg <- temp_data2 %>%
  group_by(Month) %>%
  summarise(TemperatureCAvg_monthly = mean(TemperatureCAvg, na.rm = TRUE))

# Merge the average temperature data with the original dataset
temp_data2new <- merge(temp_data2, temp_monthly_avg, by.x = "Month", by.y = "Month", all.x = TRUE)
colnames(temp_data2new)

```
```{r}

# Selected variables from temp_data2new
selected_variables <- c("Month","TemperatureCAvg_monthly", "HrAvg", "WindkmhInt", "PresslevHp",
                        "Precmm", "TotClOct", "SunD1h", "VisKm")

# Subset temp_data2new with selected variables
selected_data <- temp_data2new[, selected_variables]


# Calculate the correlation matrix
correlation_matrix <- cor(selected_data, use = "complete.obs")

#correlation matrix for visualization
melted_correlation <- melt(correlation_matrix)

# Plot the heat map
heatmap_plot <- ggplot(melted_correlation, aes(Var1, Var2, fill = value)) +
  geom_tile(color = "white") +
  scale_fill_gradient2(low = "blue", mid = "white", high = "red", midpoint = 0, limits = c(-1, 1),
                       name = "Correlation") +
  labs(title = "Correlation Heatmap of Selected Variables",
       x = "Variables", y = "Variables") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1),
        legend.position = "right")

# Print the heatmap
print(heatmap_plot)
```
The correlation heat map shows the relationship between each variable (columns). We can see a positive correlation with TotClOct and HrAvg, Viskm and temperature, etc. It shows that temperature, visibility, and sunlight range are positively correlated.Humidity(HrAvg) is more related to rainfall(Precmm) and cloudiness(TotClOct)etc. sunlight, humidity, and temperature are negatively correlated. Zero correlation can be seen in speed, humidity, visibility, etc. The correlation map shows how the two scales are related to each other affecting the climate. 

```{r}
# Analysis on the weather trends and crime in colchester for year 2023
# Group by category and count the occurrences
category_counts <- crime_data1 %>%
  group_by(category) %>%
  summarise(total_count = n())

# Get the top 5 categories
top_categories <- category_counts %>%
  top_n(5, total_count) %>%
  pull(category)

# Filter the data for only the top 5 categories
top_categories_data <- crime_data1 %>%
  filter(category %in% top_categories)

# Group by month and category, and count the occurrences
monthly_category_counts <- top_categories_data %>%
  group_by(month, category) %>%
  summarise(count = n())

# Plot the time series for top 5 categories
category_plot <- ggplot(monthly_category_counts, aes(x = month, y = count, color = category)) +
  geom_line() +
  labs(title = "Time Series of Top 5 Categories of Crime for the Year 2023",
       x = "Month", y = "Count") +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +  # Setting breaks and labels for months
  theme_minimal()

# selecting temp_data2 columns 'Month', 'TemperatureCAvg', and 'VisKm'
temp_plot <- ggplot(temp_data2, aes(x = Month)) +
  geom_line(aes(y = TemperatureCAvg, color = "TemperatureCAvg"), size = 1) +
  geom_line(aes(y = VisKm, color = "VisKm"), linetype = "dashed", size = 1) +
  labs(title = "Time Series of TemperatureCAvg and VisKm for the year 2023",
       x = "Month", y = "Value") +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +  # Set breaks and labels for months
  scale_color_manual(name = "Variables",
                     values = c("TemperatureCAvg" = "blue", "VisKm" = "orange"),
                     labels = c("TemperatureCAvg", "VisKm")) +
  theme_minimal()

# Combine both plots
combined_plot <- grid.arrange(category_plot, temp_plot, ncol = 1)

```
This time series shows the trend of weather and crime in Colchester for the year 2023. We are considering the top 5 categories of crime from crime_data1 and visibility and average temperature is considered from the temp_data2 file. We see the violent crimes category records the highest in the crime category. When it comes to trends visibility and temperature averages are more related. When visibility is lower in winter and higher in summer. While temperatures tend to be lower in winter and higher in summer.  The visibility keeps fluctuating while the temperature keeps a moderate trend. During September anti social behavior and violent crimes are high. We can see the crime rates in December and January tend to be higher and temperature seems to be low. Similarly, in June and July, we can see the crime rates increasing again and the temperature also increasing.

This clearly shows how temperature and visibility impact the crime rates in Colchester. When the visibility and temperature are low, the crime rate tends to increase. Also during summer when the temperature is high, people become aggressive, and again crime rate seems to increase.


```{r}
## after implementing smoothing technique - random walk

# Group by category and count the occurrences
category_counts <- crime_data1 %>%
  group_by(category) %>%
  summarise(total_count = n())

# Get the top 5 categories
top_categories <- category_counts %>%
  top_n(5, total_count) %>%
  pull(category)

# Filter the data for only the top 5 categories
top_categories_data <- crime_data1 %>%
  filter(category %in% top_categories)

# Group by month and category, and count the occurrences
monthly_category_counts <- top_categories_data %>%
  group_by(month, category) %>%
  summarise(count = n(), .groups = "drop")  # Remove grouping

# Plot the time series for top 5 categories with random walk smoothing
category_plot <- ggplot(monthly_category_counts, aes(x = month, y = count, color = category)) +
  geom_step() +  # Use geom_step for random walk smoothing
  labs(title = "Time series of top 5 categories of crime with random walk smoothing",
       x = "Month", y = "Count") +
  scale_x_continuous(breaks = 1:12, labels = month.abb) +
  theme_minimal()

# selecting columns 'Month', 'TemperatureCAvg', and 'VisKm' with random walk smoothing
temp_plot <- ggplot(temp_data2, aes(x = Month)) +
  geom_step(aes(y = TemperatureCAvg, color = "TemperatureCAvg"), size = 1) +  # Random walk smoothing for TemperatureCAvg
  geom_step(aes(y = VisKm, color = "VisKm"), linetype = "dashed", size = 1) +  # Random walk smoothing for VisKm
  labs(title = "Time series of temperatureCAvg and visKm with random walk smoothing",
       x = "Month", y = "Value") +
  scale_x_continuous(breaks = 1:12, labels = month.abb) + 
  scale_color_manual(name = "Variables",
                     values = c("TemperatureCAvg" = "blue", "VisKm" = "orange"),
                     labels = c("TemperatureCAvg", "VisKm")) +
  theme_minimal()

# Combine both plots
combined_plot <- grid.arrange(category_plot, temp_plot, ncol = 1)

```
The smoothing technique has been implemented on the time series. The random walk method has been used to reduce fluctuations and noise in the data. The average neighboring data points are used to replace the existing data points over repeated iterations. The time series graph clearly shows a clear trend of the crimes, temperature, and visibility over the months. The random walk technique was more effective than the Loess method and moving average smoothing method on this data.

Conclusion:

The crime and weather data of Colchester for the year 2023 have been analyzed. There are very helpful insights for policing the Colchester areas. The categorical crime rates across Colchester are impacted by the weather. When the temperature is extreme such as too low in December and January, the visibility is also low which influences to have more crime rates across Colchester.In September and October when the rainfall increases, we can see the crime rates increasing. During summer, months like June and July see high temperatures which make it more prone for people to hang out so violent crimes, anti-social behavior, and shoplifting crimes tend to be spotted in increasing trends. So more patrols and policing have been in place during January, June, July, September, October, and December.


